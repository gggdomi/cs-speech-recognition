{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "from utils import which_set, BASE_TRAIN_FOLDER_SPEC, BASE_TRAIN_FOLDER_WAV, labels_to_ints\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sets(set_name):\n",
    "    x = []\n",
    "    y = []\n",
    "    folder = os.path.join(BASE_TRAIN_FOLDER_SPEC, set_name)\n",
    "    i = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.startswith('.'):\n",
    "            continue\n",
    "        label = filename.split('.')[0]\n",
    "        inputs = np.load(os.path.join(folder, filename))\n",
    "        y.append([labels_to_ints[label]] * len(inputs))\n",
    "        x.append(inputs)\n",
    "        i += 1\n",
    "    \n",
    "    x = np.concatenate(x)\n",
    "    x = np.expand_dims(x, -1) # needed by ResNet\n",
    "    y = to_categorical(np.concatenate(y), num_classes=len(labels_to_ints))\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = make_sets(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51490, 128, 16, 1), (51490, 31))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = make_sets(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6798, 128, 16, 1), (6798, 31))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = make_sets(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6835, 128, 16, 1), (6835, 31))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://github.com/chrisdinant/speech/blob/master/models.py\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.merge import Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "class ResNet():\n",
    "    \"\"\"\n",
    "    Usage: \n",
    "        sr = ResNet([4,8,16], input_size=(50,50,1), output_size=12)\n",
    "        sr.build()\n",
    "        followed by sr.m.compile(loss='categorical_crossentropy', \n",
    "                                 optimizer='adadelta', metrics=[\"accuracy\"])\n",
    "        save plotted model with: \n",
    "            keras.utils.plot_model(sr.m, to_file = '<location>.png', \n",
    "                                   show_shapes=True)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 filters_list=[], \n",
    "                 input_size=None, \n",
    "                 output_size=None,\n",
    "                 initializer='glorot_uniform'):\n",
    "        self.filters_list = filters_list\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.initializer = initializer\n",
    "        self.m = None        \n",
    "    \n",
    "    def _block(self, filters, inp):\n",
    "        \"\"\" one residual block in a ResNet\n",
    "        \n",
    "        Args:\n",
    "            filters (int): number of convolutional filters\n",
    "            inp (tf.tensor): output from previous layer\n",
    "            \n",
    "        Returns:\n",
    "            tf.tensor: output of residual block\n",
    "        \"\"\"\n",
    "        layer_1 = BatchNormalization()(inp)\n",
    "        act_1 = Activation('relu')(layer_1)\n",
    "        conv_1 = Conv2D(filters, (3,3), \n",
    "                        padding = 'same', \n",
    "                        kernel_initializer = self.initializer)(act_1)\n",
    "        layer_2 = BatchNormalization()(conv_1)\n",
    "        act_2 = Activation('relu')(layer_2)\n",
    "        conv_2 = Conv2D(filters, (3,3), \n",
    "                        padding = 'same', \n",
    "                        kernel_initializer = self.initializer)(act_2)\n",
    "        return(conv_2)\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            keras.engine.training.Model\n",
    "        \"\"\"\n",
    "        i = Input(shape = self.input_size, name = 'input')\n",
    "        x = Conv2D(self.filters_list[0], (3,3), \n",
    "                   padding = 'same', \n",
    "                   kernel_initializer = self.initializer)(i)\n",
    "        x = MaxPooling2D(padding = 'same')(x)        \n",
    "        x = Add()([self._block(self.filters_list[0], x),x])\n",
    "        x = Add()([self._block(self.filters_list[0], x),x])\n",
    "        x = Add()([self._block(self.filters_list[0], x),x])\n",
    "        if len(self.filters_list) > 1:\n",
    "            for filt in self.filters_list[1:]:\n",
    "                x = Conv2D(filt, (3,3),\n",
    "                           strides = (2,2),\n",
    "                           padding = 'same',\n",
    "                           activation = 'relu',\n",
    "                           kernel_initializer = self.initializer)(x)\n",
    "                x = Add()([self._block(filt, x),x])\n",
    "                x = Add()([self._block(filt, x),x])\n",
    "                x = Add()([self._block(filt, x),x])\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(self.output_size, activation = 'softmax')(x)\n",
    "        \n",
    "        self.m = Model(i,x)\n",
    "        return self.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://github.com/chrisdinant/speech/blob/master/train.ipynb\n",
    "input_size = x_train.shape[1:]\n",
    "filters_list = [8,16,32]\n",
    "output_size = len(labels_to_ints)\n",
    "date = '1003'\n",
    "arch = 'resnet8_16_32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "sr = ResNet(filters_list, input_size, output_size)\n",
    "sr.build()\n",
    "sr.m.compile(loss='categorical_crossentropy', \n",
    "             optimizer='adadelta', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(sr.m, \n",
    "           to_file = './models/{}_{}.png'.format(arch,date), \n",
    "           show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./models/{}_{}_best.h5'.format(arch, date),\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "   \n",
    "#earlystopping = EarlyStopping()\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = './logs/{}_{}_{}'.format(arch, date, time()), \n",
    "                          histogram_freq = 0, \n",
    "                          write_graph = True, \n",
    "                          write_images = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 51490 samples, validate on 6798 samples\n",
      "Epoch 1/5\n",
      "51490/51490 [==============================] - 223s 4ms/step - loss: 2.4627 - acc: 0.2679 - val_loss: 2.9551 - val_acc: 0.2643\n",
      "Epoch 2/5\n",
      "51490/51490 [==============================] - 225s 4ms/step - loss: 1.1988 - acc: 0.6334 - val_loss: 2.7719 - val_acc: 0.3713\n",
      "Epoch 3/5\n",
      "51490/51490 [==============================] - 257s 5ms/step - loss: 0.7386 - acc: 0.7752 - val_loss: 1.1646 - val_acc: 0.6483\n",
      "Epoch 4/5\n",
      "51490/51490 [==============================] - 251s 5ms/step - loss: 0.5781 - acc: 0.8249 - val_loss: 1.5383 - val_acc: 0.6024\n",
      "Epoch 5/5\n",
      "51490/51490 [==============================] - 228s 4ms/step - loss: 0.5014 - acc: 0.8484 - val_loss: 0.7110 - val_acc: 0.7910\n"
     ]
    }
   ],
   "source": [
    "history = sr.m.fit(x_train, \n",
    "                   y_train, \n",
    "                   batch_size = 128, \n",
    "                   epochs = 5, \n",
    "                   verbose = 1, shuffle = True, \n",
    "                   #class_weight = class_weights,\n",
    "                   validation_data = (x_val, y_val), \n",
    "                   callbacks = [checkpointer, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"logs/{date}_{arch}_history.json\", \"w\") as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51490 samples, validate on 6798 samples\n",
      "Epoch 1/3\n",
      "51490/51490 [==============================] - 264s 5ms/step - loss: 0.4476 - acc: 0.8643 - val_loss: 0.8921 - val_acc: 0.7479\n",
      "Epoch 2/3\n",
      "51490/51490 [==============================] - 227s 4ms/step - loss: 0.4108 - acc: 0.8758 - val_loss: 1.5781 - val_acc: 0.6431\n",
      "Epoch 3/3\n",
      "51490/51490 [==============================] - 210s 4ms/step - loss: 0.3741 - acc: 0.8851 - val_loss: 1.5909 - val_acc: 0.6133\n"
     ]
    }
   ],
   "source": [
    "history = sr.m.fit(x_train, \n",
    "                   y_train, \n",
    "                   batch_size = 128, \n",
    "                   epochs = 3, \n",
    "                   verbose = 1, shuffle = True, \n",
    "                   #class_weight = class_weights,\n",
    "                   validation_data = (x_val, y_val), \n",
    "                   callbacks = [checkpointer, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6835/6835 [==============================] - 8s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5919170822465865, 0.6032187272966911]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.m.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-computed weights :\n",
    "See https://keras.io/applications/#resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
